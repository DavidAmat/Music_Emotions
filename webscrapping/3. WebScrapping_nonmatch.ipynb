{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrapping: Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Database\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re #for avoiding looking at titles with starting parenthesis\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Logging\n",
    "from v_log import VLogger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "batch_num = 0\n",
    "\n",
    "# Fixed batch_size\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging\n",
    "#log = VLogger(f'Batch {batch_num}', uri_log=f\"log/WebScrap_nonmatch.log\", file_log_level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the clean database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Connect to the database CLEAN\n",
    "\n",
    "#Paths\n",
    "path_db_final = os.path.join(\"..\",\"data\",\"MSD\",\"clean.db\")\n",
    "path_sql_connection_db =  'sqlite:///' + path_db_final\n",
    "\n",
    "#Connect\n",
    "engine = db.create_engine(path_sql_connection_db)\n",
    "connection = engine.connect()\n",
    "\n",
    "#Log\n",
    "#log.info(\"1 Connect to database...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(qq, con = connection, to_df = False):\n",
    "    res = con.execute(qq)\n",
    "    if to_df:\n",
    "        return pd.DataFrame(res.fetchall())\n",
    "    else:\n",
    "        return res.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_insert(qq, con = connection):\n",
    "    try:\n",
    "        res = con.execute(qq)\n",
    "        return res\n",
    "    except:\n",
    "        return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log\n",
    "#log.info(\"2 Select all songs...\")\n",
    "\n",
    "# Take all songs and clean the titles and create a set to compare with yt titles\n",
    "df = query_db(f\"SELECT * FROM nonmatch where batch_id = {batch_num} \", to_df=True)\n",
    "df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "\n",
    "# Separate all the non alphabetical chracters with spaces, remove them and create a set of words\n",
    "df[\"query_clean_list\"] = df[\"query\"].apply(lambda x: fun_clean_title(x, prog, list_return=True))\n",
    "df[\"query_clean_list\"] = df[\"query_clean_list\"].apply(lambda x: re.sub('[^0-9a-zA-Z]+', ' ', x))\n",
    "df[\"query_clean_set\"] =  df[\"query_clean_list\"].apply(lambda x: set(x.split(\" \")))\n",
    "\n",
    "\n",
    "#Log\n",
    "#log.info(\"2 Select all songs... (Completed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>query</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>query_clean_set</th>\n",
       "      <th>query_clean_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMUOZE12903CDF721</td>\n",
       "      <td>a picture of you the bristols</td>\n",
       "      <td>0</td>\n",
       "      <td>{the, you, bristols, picture, of, a}</td>\n",
       "      <td>a picture of you the bristols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAFPWS12903CDF737</td>\n",
       "      <td>i ll be gone the bristols</td>\n",
       "      <td>0</td>\n",
       "      <td>{i, the, bristols, ll, gone, be}</td>\n",
       "      <td>i ll be gone the bristols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRVIMSB12903CDF720</td>\n",
       "      <td>so fine the bristols</td>\n",
       "      <td>0</td>\n",
       "      <td>{bristols, so, fine, the}</td>\n",
       "      <td>so fine the bristols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRDXGYA12903CDF729</td>\n",
       "      <td>who does she think she is the bristols</td>\n",
       "      <td>0</td>\n",
       "      <td>{she, is, the, bristols, who, does, think}</td>\n",
       "      <td>who does she think she is the bristols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRYESJS12903CDF730</td>\n",
       "      <td>old man mose the bristols</td>\n",
       "      <td>0</td>\n",
       "      <td>{the, bristols, old, mose, man}</td>\n",
       "      <td>old man mose the bristols</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_id                                   query  batch_id  \\\n",
       "0  TRMUOZE12903CDF721           a picture of you the bristols         0   \n",
       "1  TRAFPWS12903CDF737               i ll be gone the bristols         0   \n",
       "2  TRVIMSB12903CDF720                    so fine the bristols         0   \n",
       "3  TRDXGYA12903CDF729  who does she think she is the bristols         0   \n",
       "4  TRYESJS12903CDF730               old man mose the bristols         0   \n",
       "\n",
       "                              query_clean_set  \\\n",
       "0        {the, you, bristols, picture, of, a}   \n",
       "1            {i, the, bristols, ll, gone, be}   \n",
       "2                   {bristols, so, fine, the}   \n",
       "3  {she, is, the, bristols, who, does, think}   \n",
       "4             {the, bristols, old, mose, man}   \n",
       "\n",
       "                         query_clean_list  \n",
       "0           a picture of you the bristols  \n",
       "1               i ll be gone the bristols  \n",
       "2                    so fine the bristols  \n",
       "3  who does she think she is the bristols  \n",
       "4               old man mose the bristols  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WebScrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the non-matched titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular expression to avoid strings in MSD initiated with NOT letters\n",
    "prog = re.compile(\"^[A-Za-z]\") \n",
    "\n",
    "def fun_clean_title(titart, prog, list_return = False):\n",
    "    \"\"\"\n",
    "    Cleans the title of a MSD song to avoid () or [] or any special character\n",
    "    \"\"\"\n",
    "    # CLEANING TITLE\n",
    "    words_list = titart.split(\" \")\n",
    "    # we want to avoid words that don't start with a character\n",
    "    words_set = set()\n",
    "    words_clean = list()\n",
    "    for ww in words_list:\n",
    "        result = prog.match(ww)\n",
    "        if result is not None: # avoid starting word with parenthesis\n",
    "            if '\\\\' not in ww: #avoid non-coded characters \\x19\n",
    "                if (\")\" not in ww) and (\"(\" not in ww):\n",
    "                    words_set.add(ww.lower())\n",
    "                    words_clean.append(ww.lower())\n",
    "    if not list_return:\n",
    "        return words_set\n",
    "    else:\n",
    "        return \" \".join(words_clean)\n",
    "\n",
    "def query_yt_song(qq_song, query_set):\n",
    "        #Search that artist on youtube\n",
    "        browser.get(f\"https://www.youtube.com/results?search_query={qq_song}\")\n",
    "\n",
    "        # List all the elements in video-title\n",
    "        vid_title_elems = browser.find_elements_by_id('video-title')\n",
    "\n",
    "        # Save videos and their URL as tuple\n",
    "        for vte in vid_title_elems:\n",
    "            \n",
    "            yt_title =  vte.get_attribute(\"title\")\n",
    "            yt_href  =  vte.get_attribute('href')\n",
    "            \n",
    "            #Compare that title with the query and if coincides in all words except 1 get that href\n",
    "            if compare_song_vs_title(yt_title, query_set):\n",
    "                \n",
    "                #Make sure that the href is not a playlist (hence playlist does not have href: None)\n",
    "                if yt_href:\n",
    "                    return yt_href\n",
    "        return \"\"\n",
    "\n",
    "def compare_song_vs_title(yt_tit, query_set):\n",
    "    \n",
    "    # YOUTUBE SONG to SET (cleaned)\n",
    "    yt_set = fun_clean_title(yt_tit, prog, list_return=True) #returns a string\n",
    "    \n",
    "    #SUBSTITUTE ANY NON ALPHANUMERICA CHARACTERS by white space\n",
    "    yt_set = re.sub('[^0-9a-zA-Z]+', ' ', yt_set)\n",
    "    yt_set = set(yt_set.split(\" \")) #convert the words separated by spaces into a set\n",
    "    \n",
    "    #Maybe that set contains words with one letter, so in that case we will remove them\n",
    "    neat_query_set = set();\n",
    "    for nn in list(query_set):\n",
    "        if len(nn) > 1:\n",
    "            neat_query_set.add(nn)\n",
    "    query_set = neat_query_set; # only take the query set as the neat set without single letters or white spaces\n",
    "    \n",
    "    # Intersection\n",
    "    int_set = query_set.intersection(yt_set)\n",
    "    \n",
    "    # Compare the length of the yt_set with the query set\n",
    "    if len(int_set) >= (len(query_set) - 1): # allow one missing word in the intersection compared to the query set\n",
    "        return True\n",
    "    elif len(query_set) > 4: # if the query is bigger thatn 4, allow a intersection set coincidence of 2 words less\n",
    "        if len(int_set) >= (len(query_set) - 2):\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test = df.sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.61s/it]\u001b[A\n",
      "2it [00:02,  1.46s/it]\u001b[A\n",
      "3it [00:03,  1.38s/it]\u001b[A\n",
      "4it [00:04,  1.23s/it]\u001b[A\n",
      "5it [00:05,  1.19s/it]\u001b[A\n",
      "6it [00:06,  1.10s/it]\u001b[A\n",
      "7it [00:07,  1.05s/it]\u001b[A\n",
      "8it [00:08,  1.04s/it]\u001b[A\n",
      "9it [00:09,  1.00it/s]\u001b[A\n",
      "10it [00:10,  1.02s/it]\u001b[A\n",
      "11it [00:11,  1.03it/s]\u001b[A\n",
      "12it [00:12,  1.04s/it]\u001b[A\n",
      "13it [00:13,  1.00it/s]\u001b[A\n",
      "14it [00:14,  1.03it/s]\u001b[A\n",
      "15it [00:15,  1.03it/s]\u001b[A\n",
      "16it [00:16,  1.01s/it]\u001b[A\n",
      "17it [00:17,  1.03it/s]\u001b[A\n",
      "18it [00:18,  1.08s/it]\u001b[A\n",
      "19it [00:19,  1.04s/it]\u001b[A\n",
      "20it [00:20,  1.01it/s]\u001b[A\n",
      "21it [00:21,  1.02it/s]\u001b[A\n",
      "22it [00:22,  1.04it/s]\u001b[A\n",
      "23it [00:23,  1.05it/s]\u001b[A\n",
      "24it [00:24,  1.04it/s]\u001b[A\n",
      "25it [00:25,  1.04it/s]\u001b[A\n",
      "26it [00:26,  1.00it/s]\u001b[A\n",
      "27it [00:27,  1.03it/s]\u001b[A\n",
      "28it [00:28,  1.05it/s]\u001b[A\n",
      "29it [00:29,  1.05it/s]\u001b[A\n",
      "30it [00:30,  1.01s/it]\u001b[A\n",
      "31it [00:31,  1.02it/s]\u001b[A\n",
      "32it [00:32,  1.04s/it]\u001b[A\n",
      "33it [00:33,  1.00s/it]\u001b[A\n",
      "34it [00:34,  1.05it/s]\u001b[A\n",
      "35it [00:35,  1.03it/s]\u001b[A\n",
      "36it [00:36,  1.02s/it]\u001b[A\n",
      "37it [00:37,  1.08s/it]\u001b[A\n",
      "38it [00:38,  1.04s/it]\u001b[A\n",
      "39it [00:39,  1.00s/it]\u001b[A\n",
      "40it [00:40,  1.02it/s]\u001b[A\n",
      "41it [00:41,  1.04it/s]\u001b[A\n",
      "42it [00:42,  1.04s/it]\u001b[A\n",
      "43it [00:43,  1.02s/it]\u001b[A\n",
      "44it [00:44,  1.08s/it]\u001b[A\n",
      "45it [00:45,  1.05s/it]\u001b[A\n",
      "46it [00:46,  1.01s/it]\u001b[A\n",
      "47it [00:47,  1.01s/it]\u001b[A\n",
      "48it [00:48,  1.03it/s]\u001b[A\n",
      "49it [00:49,  1.04it/s]\u001b[A\n",
      "50it [00:50,  1.04it/s]\u001b[A\n",
      "51it [00:51,  1.06it/s]\u001b[A\n",
      "52it [00:52,  1.07it/s]\u001b[A\n",
      "53it [00:53,  1.08it/s]\u001b[A\n",
      "54it [00:54,  1.07it/s]\u001b[A\n",
      "55it [00:55,  1.05it/s]\u001b[A\n",
      "56it [00:56,  1.05it/s]\u001b[A\n",
      "57it [00:57,  1.04it/s]\u001b[A\n",
      "58it [00:58,  1.04it/s]\u001b[A\n",
      "59it [00:58,  1.06it/s]\u001b[A\n",
      "60it [00:59,  1.10it/s]\u001b[A\n",
      "61it [01:00,  1.11it/s]\u001b[A\n",
      "62it [01:01,  1.11it/s]\u001b[A\n",
      "63it [01:02,  1.08it/s]\u001b[A\n",
      "64it [01:03,  1.10it/s]\u001b[A\n",
      "65it [01:04,  1.06it/s]\u001b[A\n",
      "66it [01:05,  1.04it/s]\u001b[A\n",
      "67it [01:06,  1.05it/s]\u001b[A\n",
      "68it [01:07,  1.05s/it]\u001b[A\n",
      "69it [01:08,  1.08s/it]\u001b[A\n",
      "70it [01:09,  1.03s/it]\u001b[A\n",
      "71it [01:10,  1.11s/it]\u001b[A\n",
      "72it [01:12,  1.10s/it]\u001b[A\n",
      "73it [01:13,  1.05s/it]\u001b[A\n",
      "74it [01:14,  1.10s/it]\u001b[A\n",
      "75it [01:15,  1.04s/it]\u001b[A\n",
      "76it [01:16,  1.01s/it]\u001b[A\n",
      "77it [01:16,  1.02it/s]\u001b[A\n",
      "78it [01:17,  1.04it/s]\u001b[A\n",
      "79it [01:18,  1.08it/s]\u001b[A\n",
      "80it [01:19,  1.07it/s]\u001b[A\n",
      "81it [01:20,  1.06it/s]\u001b[A\n",
      "82it [01:21,  1.04it/s]\u001b[A\n",
      "83it [01:22,  1.06it/s]\u001b[A\n",
      "84it [01:23,  1.04it/s]\u001b[A\n",
      "85it [01:24,  1.05it/s]\u001b[A\n",
      "86it [01:25,  1.05it/s]\u001b[A\n",
      "87it [01:26,  1.05it/s]\u001b[A\n",
      "88it [01:27,  1.02it/s]\u001b[A\n",
      "89it [01:28,  1.05it/s]\u001b[A\n",
      "90it [01:29,  1.02s/it]\u001b[A\n",
      "91it [01:30,  1.01s/it]\u001b[A\n",
      "92it [01:31,  1.03it/s]\u001b[A\n",
      "93it [01:32,  1.01it/s]\u001b[A\n",
      "94it [01:33,  1.06it/s]\u001b[A\n",
      "95it [01:34,  1.06it/s]\u001b[A\n",
      "96it [01:35,  1.09it/s]\u001b[A\n",
      "97it [01:35,  1.07it/s]\u001b[A\n",
      "98it [01:37,  1.03it/s]\u001b[A\n",
      "99it [01:37,  1.08it/s]\u001b[A\n",
      "100it [01:39,  1.01it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "dict_match = dict()\n",
    "dict_nonmatch = dict()\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "\n",
    "for ii, row in tqdm.tqdm(dt_test.iterrows()):\n",
    "    track_id, query, batch_id, query_clean_set, query_clean_list = row\n",
    "    \n",
    "    # Query yt song and compare the titles with the query set\n",
    "    result = query_yt_song(query_clean_list, query_clean_set)\n",
    "    \n",
    "    # Save the cases in which we find a match\n",
    "    if len(result): #there is a href\n",
    "        dict_match[track_id] = result\n",
    "    else: #if not, only store the query done\n",
    "        dict_nonmatch[track_id] = query_clean_list\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRMUVPJ128F14AE671': 'got to b tru great advenuture album steven curtis chapman',\n",
       " 'TRVODSD128F424424F': 'bye bye baby big maceo',\n",
       " 'TRUNQIN128F423D5D7': 'outra vez charlie byrd',\n",
       " 'TRZEEAF12903CCFD79': 'beauty of the sea the gabe dixon band',\n",
       " 'TRFGCTI128E079594C': 'debussy etudes vi pour les huits doigts pierre laurent aimard',\n",
       " 'TRLNJKL128F42396B9': 'why do they never play les savy fav on the radio jetplane landing',\n",
       " 'TRDGNAI128F92E79F3': 'i m a gamblin woman memphis minnie',\n",
       " 'TRWSREF128F92EFF67': 'polka medley tiller s folly',\n",
       " 'TRPZXIS128F4275CB1': 'why do i feel wilks',\n",
       " 'TRAGWKV128F92F0F35': 'love smashed on a rock martyn bates'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_nonmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dmatch(dmatch, batch_num):\n",
    "    query_insert_string = \"insert into match values \"\n",
    "    for track_id, url in dmatch.items():\n",
    "        query_insert_string += f\"('{track_id}', '{url}', '{batch_num + 1000}'),\"\n",
    "    query_insert_string = query_insert_string[:-1]\n",
    "    query_insert_string = query_insert_string + \";\"\n",
    "    \n",
    "    # Insert\n",
    "    try:\n",
    "        res = query_insert(query_insert_string)\n",
    "        return res, query_insert_string\n",
    "    except:\n",
    "        return False, query_insert_string\n",
    "\n",
    "def insert_dnonmatch(dnonmatch, batch_num):\n",
    "    query_insert_string = \"insert into nonmatch values \"\n",
    "    for track_id, yt_query in dnonmatch.items():\n",
    "        yt_query = yt_query.replace(\"'\",\" \")\n",
    "        query_insert_string += f\"('{track_id}', '{yt_query}', '{batch_num + 1000}'),\"\n",
    "    query_insert_string = query_insert_string[:-1]\n",
    "    query_insert_string = query_insert_string + \";\"\n",
    "    \n",
    "     # Insert\n",
    "    try:\n",
    "        res = query_insert(query_insert_string)\n",
    "        return res, query_insert_string\n",
    "    except:\n",
    "        return False, query_insert_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Log\n",
    "log.info(\"6 Inserting into match and nonmatch tables...\")\n",
    "\n",
    "# Run the queries to insert info\n",
    "resmatch, qqmatch = insert_dmatch(dict_match, batch_num)\n",
    "resnonmatch, qqnonmatch = insert_dnonmatch(dict_nonmatch, batch_num)\n",
    "\n",
    "# Report errors in the logging\n",
    "if resmatch is False:\n",
    "    log.info(f\"6.1 EROR INSERTING query in match: {qqmatch}...\")\n",
    "    \n",
    "if resnonmatch is False:\n",
    "    log.info(f\"6.1 EROR INSERTING query in nonmatch: {qqnonmatch}...\")\n",
    "    \n",
    "if resmatch:\n",
    "    if resnonmatch:\n",
    "        log.info(f\"7 Succesfully scrapped Batch {batch_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
