{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate Clean.db to S3\n",
    "\n",
    "One of the parts of the projects contains working on S3, this means moving all that is being done in SQLite database to an S3 bucket, since it is the most economic version for what we want to do. What this script will do is take the clean.db and create a file system that can replicate this datbase in a S3 bucket as a file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re #for avoiding looking at titles with starting parenthesis\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from io import StringIO \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Connect to the database CLEAN\n",
    "\n",
    "#Paths\n",
    "path_db_final = os.path.join(\"..\",\"data\",\"MSD\",\"clean.db\")\n",
    "path_sql_connection_db =  'sqlite:///' + path_db_final\n",
    "\n",
    "#Connect\n",
    "engine = db.create_engine(path_sql_connection_db)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(qq, con = connection, to_df = False):\n",
    "    res = con.execute(qq)\n",
    "    if to_df:\n",
    "        return pd.DataFrame(res.fetchall())\n",
    "    else:\n",
    "        return res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create all the files from the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_max = query_db(f\"SELECT max(batch_id) FROM match where batch_id < 1000\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {1: 9500, 14: 2700} # index where the WebScrapping_nonmatch.py failed or stopped, so we note down\n",
    "# which are the last uploaded iterations of that batch (each iteration is the index in the dataframe of the track)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_S3(df, folder_path, name_file, S3_BUCKET = 'musicemotions'):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())\n",
    "    return resp\n",
    "\n",
    "def ls_S3(folder_path, S3_BUCKET = 'musicemotions', maxkeys = 1000):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    # S3 list objects\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=S3_BUCKET,\n",
    "                Prefix =folder_path,\n",
    "                MaxKeys=maxkeys )\n",
    "\n",
    "    files_inside_folder = list()\n",
    "    for contents_folder in response[\"Contents\"]:\n",
    "        \n",
    "        # Get the contents of the folder\n",
    "        file_names = contents_folder[\"Key\"].split(\"/\")[-1]\n",
    "        \n",
    "        #If the name of the file is not empty:\n",
    "        if len(file_names):\n",
    "            files_inside_folder.append(file_names)\n",
    "    return files_inside_folder\n",
    "\n",
    "def create_df_batch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "\n",
    "    #Restart from the position that was stucked\n",
    "    if batch_num in exceptions:\n",
    "        idx_start =  exceptions[batch_num]\n",
    "        df = df.iloc[idx_start:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Non-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f75bcb5f84d03aa3881cc8b66a2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. S3 - connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.csv', '1.csv', '10.csv', '11.csv', '12.csv', '13.csv', '14.csv',\n",
       "       '15.csv', '16.csv', '17.csv', '18.csv', '19.csv', '2.csv',\n",
       "       '20.csv', '21.csv', '22.csv', '23.csv', '24.csv', '25.csv',\n",
       "       '26.csv', '27.csv', '28.csv', '29.csv', '3.csv', '30.csv',\n",
       "       '31.csv', '32.csv', '33.csv', '34.csv', '35.csv', '4.csv', '5.csv',\n",
       "       '6.csv', '7.csv', '8.csv', '9.csv'], dtype='<U6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ls_S3(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = '1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_s3(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = load_df_s3(folder_path, name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>query</th>\n",
       "      <th>batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRLMHCX128F42AAE0B</td>\n",
       "      <td>watche the packard ruxpin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRLMHUX128F9310E7F</td>\n",
       "      <td>long way home redstar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRLMHYE128F42BCA84</td>\n",
       "      <td>where are you baby? betty boo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRLMJGU12903CF56AA</td>\n",
       "      <td>culture vulture chicks on speed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRLMKBP12903CEBFCE</td>\n",
       "      <td>cuachin ghleann neifin joe &amp; antoinette mckenna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11906</th>\n",
       "      <td>TRZZZCL128F428BB80</td>\n",
       "      <td>the ship of pills and needed things i am ghost</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11907</th>\n",
       "      <td>TRZZZCU12903CE6D49</td>\n",
       "      <td>funny how galliano</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>TRZZZED128F930FBBA</td>\n",
       "      <td>nothings wrong the chelsea smiles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11909</th>\n",
       "      <td>TRZZZET128F9337FD9</td>\n",
       "      <td>parade of fools (live at the basement_ 2005) k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11910</th>\n",
       "      <td>TRZZZVZ12903CD9485</td>\n",
       "      <td>nothin  but a fool (from the album west coast ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11911 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                              query  \\\n",
       "0      TRLMHCX128F42AAE0B                          watche the packard ruxpin   \n",
       "1      TRLMHUX128F9310E7F                              long way home redstar   \n",
       "2      TRLMHYE128F42BCA84                      where are you baby? betty boo   \n",
       "3      TRLMJGU12903CF56AA                    culture vulture chicks on speed   \n",
       "4      TRLMKBP12903CEBFCE    cuachin ghleann neifin joe & antoinette mckenna   \n",
       "...                   ...                                                ...   \n",
       "11906  TRZZZCL128F428BB80     the ship of pills and needed things i am ghost   \n",
       "11907  TRZZZCU12903CE6D49                                 funny how galliano   \n",
       "11908  TRZZZED128F930FBBA                  nothings wrong the chelsea smiles   \n",
       "11909  TRZZZET128F9337FD9  parade of fools (live at the basement_ 2005) k...   \n",
       "11910  TRZZZVZ12903CD9485  nothin  but a fool (from the album west coast ...   \n",
       "\n",
       "       batch_id  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "...         ...  \n",
       "11906         1  \n",
       "11907         1  \n",
       "11908         1  \n",
       "11909         1  \n",
       "11910         1  \n",
       "\n",
       "[11911 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df_nonmatch.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
