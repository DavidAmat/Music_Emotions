{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate Clean.db to S3\n",
    "\n",
    "One of the parts of the projects contains working on S3, this means moving all that is being done in SQLite database to an S3 bucket, since it is the most economic version for what we want to do. What this script will do is take the clean.db and create a file system that can replicate this datbase in a S3 bucket as a file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re #for avoiding looking at titles with starting parenthesis\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from io import StringIO \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Connect to the database CLEAN\n",
    "\n",
    "#Paths\n",
    "path_db_final = os.path.join(\"..\",\"data\",\"MSD\",\"clean.db\")\n",
    "path_sql_connection_db =  'sqlite:///' + path_db_final\n",
    "\n",
    "#Connect\n",
    "engine = db.create_engine(path_sql_connection_db)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(qq, con = connection, to_df = False):\n",
    "    res = con.execute(qq)\n",
    "    if to_df:\n",
    "        return pd.DataFrame(res.fetchall())\n",
    "    else:\n",
    "        return res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create all the files from the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_max = query_db(f\"SELECT max(batch_id) FROM match where batch_id < 1000\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {1: 9500, 14: 2700} # index where the WebScrapping_nonmatch.py failed or stopped, so we note down\n",
    "# which are the last uploaded iterations of that batch (each iteration is the index in the dataframe of the track)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_S3(df, folder_path, name_file, S3_BUCKET = 'musicemotions'):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())\n",
    "    return resp\n",
    "\n",
    "def ls_S3(folder_path, S3_BUCKET = 'musicemotions', maxkeys = 1000):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    # S3 list objects\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=S3_BUCKET,\n",
    "                Prefix =folder_path,\n",
    "                MaxKeys=maxkeys )\n",
    "\n",
    "    files_inside_folder = list()\n",
    "    for contents_folder in response[\"Contents\"]:\n",
    "        \n",
    "        # Get the contents of the folder\n",
    "        file_names = contents_folder[\"Key\"].split(\"/\")[-1]\n",
    "        \n",
    "        #If the name of the file is not empty:\n",
    "        if len(file_names):\n",
    "            files_inside_folder.append(file_names)\n",
    "    return files_inside_folder\n",
    "\n",
    "def create_df_batch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "\n",
    "    #Restart from the position that was stucked\n",
    "    if batch_num in exceptions:\n",
    "        idx_start =  exceptions[batch_num]\n",
    "        df = df.iloc[idx_start:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Non-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f75bcb5f84d03aa3881cc8b66a2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. S3 - connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.csv', '1.csv', '10.csv', '11.csv', '12.csv', '13.csv', '14.csv',\n",
       "       '15.csv', '16.csv', '17.csv', '18.csv', '19.csv', '2.csv',\n",
       "       '20.csv', '21.csv', '22.csv', '23.csv', '24.csv', '25.csv',\n",
       "       '26.csv', '27.csv', '28.csv', '29.csv', '3.csv', '30.csv',\n",
       "       '31.csv', '32.csv', '33.csv', '34.csv', '35.csv', '4.csv', '5.csv',\n",
       "       '6.csv', '7.csv', '8.csv', '9.csv'], dtype='<U6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ls_S3(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = '0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_s3(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = load_df_s3(folder_path, name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>query</th>\n",
       "      <th>batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAAZU128F4226F7A</td>\n",
       "      <td>stop laughing moose</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAADHC128F4227F6B</td>\n",
       "      <td>let them come to berlin the weathermen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAAFFR128F42719EA</td>\n",
       "      <td>bokstavelig talt (skit) tungtvann</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAAFJW128F428A424</td>\n",
       "      <td>stickin in my eye nofx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAAFXF128F4267A2A</td>\n",
       "      <td>brother mine eric schwartz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20469</th>\n",
       "      <td>TRZZXHU12903CF4706</td>\n",
       "      <td>whoa we the kings</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20470</th>\n",
       "      <td>TRZZXVN128F93285B4</td>\n",
       "      <td>abschied asp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>TRZZYLO12903CAC06C</td>\n",
       "      <td>i ve never seen the righteous forsaken dallas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>TRZZZTZ128F92C5A5F</td>\n",
       "      <td>for your eyes only (performed by dea li) holly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>TRZZZVF12903CE3E28</td>\n",
       "      <td>wedding ring phantom limbs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20474 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                                              query  \\\n",
       "0      TRAAAZU128F4226F7A                                stop laughing moose   \n",
       "1      TRAADHC128F4227F6B             let them come to berlin the weathermen   \n",
       "2      TRAAFFR128F42719EA                  bokstavelig talt (skit) tungtvann   \n",
       "3      TRAAFJW128F428A424                             stickin in my eye nofx   \n",
       "4      TRAAFXF128F4267A2A                         brother mine eric schwartz   \n",
       "...                   ...                                                ...   \n",
       "20469  TRZZXHU12903CF4706                                  whoa we the kings   \n",
       "20470  TRZZXVN128F93285B4                                       abschied asp   \n",
       "20471  TRZZYLO12903CAC06C  i ve never seen the righteous forsaken dallas ...   \n",
       "20472  TRZZZTZ128F92C5A5F  for your eyes only (performed by dea li) holly...   \n",
       "20473  TRZZZVF12903CE3E28                         wedding ring phantom limbs   \n",
       "\n",
       "       batch_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "20469         0  \n",
       "20470         0  \n",
       "20471         0  \n",
       "20472         0  \n",
       "20473         0  \n",
       "\n",
       "[20474 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df_nonmatch.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
