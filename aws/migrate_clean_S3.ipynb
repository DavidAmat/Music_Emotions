{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate Clean.db to S3\n",
    "\n",
    "One of the parts of the projects contains working on S3, this means moving all that is being done in SQLite database to an S3 bucket, since it is the most economic version for what we want to do. What this script will do is take the clean.db and create a file system that can replicate this datbase in a S3 bucket as a file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e911898e75b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "# Database\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re #for avoiding looking at titles with starting parenthesis\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from io import StringIO \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:\\Users\\David\\Anaconda3\\python.EXE\n"
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Connect to the database CLEAN\n",
    "\n",
    "#Paths\n",
    "path_db_final = os.path.join(\"..\",\"data\",\"MSD\",\"clean.db\")\n",
    "path_sql_connection_db =  'sqlite:///' + path_db_final\n",
    "\n",
    "#Connect\n",
    "engine = db.create_engine(path_sql_connection_db)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(qq, con = connection, to_df = False):\n",
    "    res = con.execute(qq)\n",
    "    if to_df:\n",
    "        return pd.DataFrame(res.fetchall())\n",
    "    else:\n",
    "        return res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create all the files from the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_max = query_db(f\"SELECT max(batch_id) FROM match where batch_id < 1000\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {1: 9500, 14: 2700} # index where the WebScrapping_nonmatch.py failed or stopped, so we note down\n",
    "# which are the last uploaded iterations of that batch (each iteration is the index in the dataframe of the track)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_S3(df, folder_path, name_file, S3_BUCKET = 'musicemotions'):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())\n",
    "    return resp\n",
    "\n",
    "def ls_S3(folder_path, S3_BUCKET = 'musicemotions', maxkeys = 1000):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    # S3 list objects\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=S3_BUCKET,\n",
    "                Prefix =folder_path,\n",
    "                MaxKeys=maxkeys )\n",
    "\n",
    "    files_inside_folder = list()\n",
    "    for contents_folder in response[\"Contents\"]:\n",
    "        \n",
    "        # Get the contents of the folder\n",
    "        file_names = contents_folder[\"Key\"].split(\"/\")[-1]\n",
    "        \n",
    "        #If the name of the file is not empty:\n",
    "        if len(file_names):\n",
    "            files_inside_folder.append(file_names)\n",
    "    return files_inside_folder\n",
    "\n",
    "def create_df_batch_nonmatch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "\n",
    "    #Restart from the position that was stucked\n",
    "    if batch_num in exceptions:\n",
    "        idx_start =  exceptions[batch_num]\n",
    "        df = df.iloc[idx_start:]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_df_batch_match(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    batch_num_nonmatch = batch_num + 1000\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM match where batch_id in ({batch_num}, {batch_num_nonmatch})\", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"url\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "    return df\n",
    "\n",
    "def create_df_batch_nonmatch_nonmatch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    batch_num_nonmatch = batch_num + 1000\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num_nonmatch} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Migration of Non-Match: queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ls_S3(folder_path, S3_BUCKET = 'musicemotions', maxkeys = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f75bcb5f84d03aa3881cc8b66a2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_nonmatch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.csv', '1.csv', '10.csv', '11.csv', '12.csv', '13.csv', '14.csv',\n",
       "       '15.csv', '16.csv', '17.csv', '18.csv', '19.csv', '2.csv',\n",
       "       '20.csv', '21.csv', '22.csv', '23.csv', '24.csv', '25.csv',\n",
       "       '26.csv', '27.csv', '28.csv', '29.csv', '3.csv', '30.csv',\n",
       "       '31.csv', '32.csv', '33.csv', '34.csv', '35.csv', '4.csv', '5.csv',\n",
       "       '6.csv', '7.csv', '8.csv', '9.csv'], dtype='<U6')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ls_S3(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Migration of Match: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"match-results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72784dde3004253aa7d1c1c781ed93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_match(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Migration of NonMatched: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d88348ed07d4ed9b55494453a885689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-f3603d7490ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_max\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf_b_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df_batch_nonmatch_nonmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_df_to_S3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_b_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{b_num}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-ad1d9c53acf2>\u001b[0m in \u001b[0;36mcreate_df_batch_nonmatch_nonmatch\u001b[1;34m(batch_num)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num_nonmatch} \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"track_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"query\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"batch_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mdf\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"track_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise ValueError(\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_nonmatch_nonmatch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = '35.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_s3(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = load_df_s3(folder_path, name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>url</th>\n",
       "      <th>batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAXRN128F4214AC9</td>\n",
       "      <td>https://www.youtube.com/watch?v=QelLZOMnUqY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRABOED12903D0DB16</td>\n",
       "      <td>https://www.youtube.com/watch?v=Nv2v45D7nyM</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRADCBW12903CEFFAA</td>\n",
       "      <td>https://www.youtube.com/watch?v=IiBXhTLbwRo</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRADDAQ12903CBBEA4</td>\n",
       "      <td>https://www.youtube.com/watch?v=lN8uDYyNgxY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAEHMU128F92FAE6E</td>\n",
       "      <td>https://www.youtube.com/watch?v=6SSz97zGiyA</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>TRZXBEH128F4239266</td>\n",
       "      <td>https://www.youtube.com/watch?v=K_GYy7Zfiig</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>TRZXNZF128F931EDF3</td>\n",
       "      <td>https://www.youtube.com/watch?v=q5DnGxNQExE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>TRZZANS128F426808A</td>\n",
       "      <td>https://www.youtube.com/watch?v=L0zjCMMbnjo</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>TRZZIGO128F1499EE9</td>\n",
       "      <td>https://www.youtube.com/watch?v=jVtYa-MnOIY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>TRZZQOX12903CB32E2</td>\n",
       "      <td>https://www.youtube.com/watch?v=mZ6XyCVJQ38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               track_id                                          url  batch_id\n",
       "0    TRAAXRN128F4214AC9  https://www.youtube.com/watch?v=QelLZOMnUqY        35\n",
       "1    TRABOED12903D0DB16  https://www.youtube.com/watch?v=Nv2v45D7nyM        35\n",
       "2    TRADCBW12903CEFFAA  https://www.youtube.com/watch?v=IiBXhTLbwRo        35\n",
       "3    TRADDAQ12903CBBEA4  https://www.youtube.com/watch?v=lN8uDYyNgxY        35\n",
       "4    TRAEHMU128F92FAE6E  https://www.youtube.com/watch?v=6SSz97zGiyA        35\n",
       "..                  ...                                          ...       ...\n",
       "826  TRZXBEH128F4239266  https://www.youtube.com/watch?v=K_GYy7Zfiig        35\n",
       "827  TRZXNZF128F931EDF3  https://www.youtube.com/watch?v=q5DnGxNQExE        35\n",
       "828  TRZZANS128F426808A  https://www.youtube.com/watch?v=L0zjCMMbnjo        35\n",
       "829  TRZZIGO128F1499EE9  https://www.youtube.com/watch?v=jVtYa-MnOIY        35\n",
       "830  TRZZQOX12903CB32E2  https://www.youtube.com/watch?v=mZ6XyCVJQ38        35\n",
       "\n",
       "[831 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load any file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Google Drive\\25. SaturdaysAI\\0_Project\\project\\aws\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\webscrapping\\\\log\\\\WebScrap.log'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df_nonmatch.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_S3(local_path, S3_path,  S3_BUCKET = 'musicemotions'):\n",
    "    \"\"\"\n",
    "    local_path = os.path.join(\"..\",\"webscrapping\",\"log\",\"WebScrap.log\")\n",
    "    S3_path = nonmatch-query/log.txt\n",
    "    \"\"\"\n",
    "    if S3_path:\n",
    "        s3 = boto3.resource('s3')\n",
    "        resp = s3.Object(S3_BUCKET, S3_path).put(Body=open(local_path, 'rb'))\n",
    "    else:\n",
    "        s3 = boto3.resource('s3')\n",
    "        resp = s3.Object(S3_BUCKET, S3_path).put(Body=open(local_path, 'rb'))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3_to_obj(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = list()\n",
    "with open(os.path.join(\"..\",\"webscrapping\",\"log\",\"WebScrap.log\"),'r') as f:\n",
    "    for line in f.readlines():\n",
    "        content.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = \"\\\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "resp = s3.Object(S3_BUCKET, \"prova.txt\").put(Body=all_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatch = {\"TR1\": \"yjkalskdalk\", \"TR2\": \"akasdjkaslk\", \"TR3\": \"asldkasjldkasld\"}\n",
    "batch_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmatch_to_df(dmatch, batch_num):\n",
    "    df_match = pd.DataFrame(dmatch.items())\n",
    "    df_match.columns = [\"track_id\", \"url\"]\n",
    "    df_match[\"batch_id\"] = batch_num\n",
    "    return df_match\n",
    "\n",
    "def dnonmatch_to_df(dnonmatch, batch_num):\n",
    "    df_match = pd.DataFrame(dnonmatch.items())\n",
    "    df_match.columns = [\"track_id\", \"query\"]\n",
    "    df_match[\"batch_id\"] = batch_num\n",
    "    return df_match\n",
    "\n",
    "def dmatch_to_S3(dmatch, dnonmatch, batch_num, folder_path = \"match-results\", folder_path_nonmatch = \"nonmatch-results\"):\n",
    "    \n",
    "    # Get the S3 file with that name\n",
    "    name_file = f'{batch_num}.csv'\n",
    "    df_S3 = load_df_s3(folder_path, name_file)\n",
    "    \n",
    "    # Get the dmatch and convert it to dataframe\n",
    "    df_match = dmatch_to_df(dmatch, batch_num)\n",
    "    df_nonmatch = dmatch_to_df(dnonmatch, batch_num)\n",
    "    \n",
    "    # Join the existing df in S3 with the df_match for that iteration\n",
    "    df_concat = pd.concat([df_S3, df_match], axis=0)\n",
    "    \n",
    "    # Save DMATCH to S3\n",
    "    res = save_df_to_S3(df_concat, folder_path, name_file, S3_BUCKET = 'musicemotions')\n",
    "    \n",
    "    # Save DF_NONMATCH to S3 in \n",
    "    res2 = save_df_to_S3(df_nonmatch, folder_path_nonmatch, name_file, S3_BUCKET = 'musicemotions')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TR1': 'yjkalskdalk', 'TR2': 'akasdjkaslk', 'TR3': 'asldkasjldkasld'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3DA6722606625BD7',\n",
       "  'HostId': 'PZ3EuzMjd83Tg+hwyjWfpe8Y1xiR0QByMMVPDL/FClv2Oz6jh0h7xseB8r9U/LYEnJWRYYke93g=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'PZ3EuzMjd83Tg+hwyjWfpe8Y1xiR0QByMMVPDL/FClv2Oz6jh0h7xseB8r9U/LYEnJWRYYke93g=',\n",
       "   'x-amz-request-id': '3DA6722606625BD7',\n",
       "   'date': 'Sun, 29 Mar 2020 17:52:25 GMT',\n",
       "   'etag': '\"e0793500eb7f2b14522c04d9c82ca471\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e0793500eb7f2b14522c04d9c82ca471\"'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df_to_S3(df_concat, \"\", \"test_bucket.csv\", S3_BUCKET = 'musicemotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}