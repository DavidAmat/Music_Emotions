{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrate Clean.db to S3\n",
    "\n",
    "One of the parts of the projects contains working on S3, this means moving all that is being done in SQLite database to an S3 bucket, since it is the most economic version for what we want to do. What this script will do is take the clean.db and create a file system that can replicate this datbase in a S3 bucket as a file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re #for avoiding looking at titles with starting parenthesis\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from io import StringIO \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Connect to the database CLEAN\n",
    "\n",
    "#Paths\n",
    "path_db_final = os.path.join(\"..\",\"data\",\"MSD\",\"clean.db\")\n",
    "path_sql_connection_db =  'sqlite:///' + path_db_final\n",
    "\n",
    "#Connect\n",
    "engine = db.create_engine(path_sql_connection_db)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(qq, con = connection, to_df = False):\n",
    "    res = con.execute(qq)\n",
    "    if to_df:\n",
    "        return pd.DataFrame(res.fetchall())\n",
    "    else:\n",
    "        return res.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create all the files from the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_max = query_db(f\"SELECT max(batch_id) FROM match where batch_id < 1000\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {1: 9500, 14: 2700} # index where the WebScrapping_nonmatch.py failed or stopped, so we note down\n",
    "# which are the last uploaded iterations of that batch (each iteration is the index in the dataframe of the track)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_S3(df, folder_path, name_file, S3_BUCKET = 'musicemotions'):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())\n",
    "    return resp\n",
    "\n",
    "def ls_S3(folder_path, S3_BUCKET = 'musicemotions', maxkeys = 1000):\n",
    "    #Connect to S3\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    \n",
    "    # S3 list objects\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=S3_BUCKET,\n",
    "                Prefix =folder_path,\n",
    "                MaxKeys=maxkeys )\n",
    "\n",
    "    files_inside_folder = list()\n",
    "    for contents_folder in response[\"Contents\"]:\n",
    "        \n",
    "        # Get the contents of the folder\n",
    "        file_names = contents_folder[\"Key\"].split(\"/\")[-1]\n",
    "        \n",
    "        #If the name of the file is not empty:\n",
    "        if len(file_names):\n",
    "            files_inside_folder.append(file_names)\n",
    "    return files_inside_folder\n",
    "\n",
    "def create_df_batch_nonmatch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "\n",
    "    #Restart from the position that was stucked\n",
    "    if batch_num in exceptions:\n",
    "        idx_start =  exceptions[batch_num]\n",
    "        df = df.iloc[idx_start:]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_df_batch_match(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    batch_num_nonmatch = batch_num + 1000\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM match where batch_id in ({batch_num}, {batch_num_nonmatch})\", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"url\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "    return df\n",
    "\n",
    "def create_df_batch_nonmatch_nonmatch(batch_num):\n",
    "    # Take all songs and clean the titles and create a set to compare with yt titles\n",
    "    batch_num_nonmatch = batch_num + 1000\n",
    "    df = query_db(f\"SELECT DISTINCT * FROM nonmatch where batch_id = {batch_num_nonmatch} \", to_df=True)\n",
    "\n",
    "    df.columns = [\"track_id\", \"query\",\"batch_id\"]\n",
    "    df  = df.sort_values([\"track_id\"])\n",
    "    df.index = np.arange(1, df.shape[0] + 1, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Migration of Non-Match: queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57f75bcb5f84d03aa3881cc8b66a2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_nonmatch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 - connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.csv', '1.csv', '10.csv', '11.csv', '12.csv', '13.csv', '14.csv',\n",
       "       '15.csv', '16.csv', '17.csv', '18.csv', '19.csv', '2.csv',\n",
       "       '20.csv', '21.csv', '22.csv', '23.csv', '24.csv', '25.csv',\n",
       "       '26.csv', '27.csv', '28.csv', '29.csv', '3.csv', '30.csv',\n",
       "       '31.csv', '32.csv', '33.csv', '34.csv', '35.csv', '4.csv', '5.csv',\n",
       "       '6.csv', '7.csv', '8.csv', '9.csv'], dtype='<U6')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ls_S3(folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Migration of Match: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"match-results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\david\\.virtualenvs\\project-pfx4texb\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72784dde3004253aa7d1c1c781ed93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_match(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Migration of NonMatched: results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"nonmatch-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b_num in tqdm.tqdm_notebook(range(0,batch_max + 1)):\n",
    "    df_b_num = create_df_batch_nonmatch_nonmatch(b_num)\n",
    "    res = save_df_to_S3(df_b_num, folder_path, f'{b_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = '35.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_s3(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = load_df_s3(folder_path, name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>url</th>\n",
       "      <th>batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAXRN128F4214AC9</td>\n",
       "      <td>https://www.youtube.com/watch?v=QelLZOMnUqY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRABOED12903D0DB16</td>\n",
       "      <td>https://www.youtube.com/watch?v=Nv2v45D7nyM</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRADCBW12903CEFFAA</td>\n",
       "      <td>https://www.youtube.com/watch?v=IiBXhTLbwRo</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRADDAQ12903CBBEA4</td>\n",
       "      <td>https://www.youtube.com/watch?v=lN8uDYyNgxY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAEHMU128F92FAE6E</td>\n",
       "      <td>https://www.youtube.com/watch?v=6SSz97zGiyA</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>TRZXBEH128F4239266</td>\n",
       "      <td>https://www.youtube.com/watch?v=K_GYy7Zfiig</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>TRZXNZF128F931EDF3</td>\n",
       "      <td>https://www.youtube.com/watch?v=q5DnGxNQExE</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>TRZZANS128F426808A</td>\n",
       "      <td>https://www.youtube.com/watch?v=L0zjCMMbnjo</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>TRZZIGO128F1499EE9</td>\n",
       "      <td>https://www.youtube.com/watch?v=jVtYa-MnOIY</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>TRZZQOX12903CB32E2</td>\n",
       "      <td>https://www.youtube.com/watch?v=mZ6XyCVJQ38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               track_id                                          url  batch_id\n",
       "0    TRAAXRN128F4214AC9  https://www.youtube.com/watch?v=QelLZOMnUqY        35\n",
       "1    TRABOED12903D0DB16  https://www.youtube.com/watch?v=Nv2v45D7nyM        35\n",
       "2    TRADCBW12903CEFFAA  https://www.youtube.com/watch?v=IiBXhTLbwRo        35\n",
       "3    TRADDAQ12903CBBEA4  https://www.youtube.com/watch?v=lN8uDYyNgxY        35\n",
       "4    TRAEHMU128F92FAE6E  https://www.youtube.com/watch?v=6SSz97zGiyA        35\n",
       "..                  ...                                          ...       ...\n",
       "826  TRZXBEH128F4239266  https://www.youtube.com/watch?v=K_GYy7Zfiig        35\n",
       "827  TRZXNZF128F931EDF3  https://www.youtube.com/watch?v=q5DnGxNQExE        35\n",
       "828  TRZZANS128F426808A  https://www.youtube.com/watch?v=L0zjCMMbnjo        35\n",
       "829  TRZZIGO128F1499EE9  https://www.youtube.com/watch?v=jVtYa-MnOIY        35\n",
       "830  TRZZQOX12903CB32E2  https://www.youtube.com/watch?v=mZ6XyCVJQ38        35\n",
       "\n",
       "[831 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load any file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Google Drive\\25. SaturdaysAI\\0_Project\\project\\aws\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\webscrapping\\\\log\\\\WebScrap.log'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set the destination path\n",
    "    path_S3 = folder_path + \"/\" + name_file\n",
    "    \n",
    "    # Buffer dataframe to upload\n",
    "    csv_buffer = StringIO()\n",
    "    df_nonmatch.to_csv(csv_buffer, index = False)\n",
    "\n",
    "    resp = s3.put_object(Bucket = S3_BUCKET, Key = path_S3, Body = csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_S3(local_path, S3_path,  S3_BUCKET = 'musicemotions'):\n",
    "    \"\"\"\n",
    "    local_path = os.path.join(\"..\",\"webscrapping\",\"log\",\"WebScrap.log\")\n",
    "    S3_path = nonmatch-query/log.txt\n",
    "    \"\"\"\n",
    "    if S3_path:\n",
    "        s3 = boto3.resource('s3')\n",
    "        resp = s3.Object(S3_BUCKET, S3_path).put(Body=open(local_path, 'rb'))\n",
    "    else:\n",
    "        s3 = boto3.resource('s3')\n",
    "        resp = s3.Object(S3_BUCKET, S3_path).put(Body=open(local_path, 'rb'))\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S3_to_obj(folder_path, file_name, S3_BUCKET = 'musicemotions'):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    path_S3 = folder_path + \"/\" + file_name  \n",
    "    csv_obj = s3.get_object(Bucket = S3_BUCKET,  Key = path_S3)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = list()\n",
    "with open(os.path.join(\"..\",\"webscrapping\",\"log\",\"WebScrap.log\"),'r') as f:\n",
    "    for line in f.readlines():\n",
    "        content.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = \"\\\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "resp = s3.Object(S3_BUCKET, \"prova.txt\").put(Body=all_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dict = {\"TR1\": \"yjkalskdalk\", \"TR2\": \"akasdjkaslk\", \"TR3\": \"asldkasjldkasld\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TR1</td>\n",
       "      <td>yjkalskdalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR2</td>\n",
       "      <td>akasdjkaslk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TR3</td>\n",
       "      <td>asldkasjldkasld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                1\n",
       "0  TR1      yjkalskdalk\n",
       "1  TR2      akasdjkaslk\n",
       "2  TR3  asldkasjldkasld"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match = pd.DataFrame(match_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
